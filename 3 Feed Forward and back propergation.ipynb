{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMBxUllIopMQ/RD9xeBAZC1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-vuKJoVTBFI","executionInfo":{"status":"ok","timestamp":1738560909458,"user_tz":-330,"elapsed":122104,"user":{"displayName":"Shreyansh Jain","userId":"06728667211778416802"}},"outputId":"bb4741e9-a051-4e74-94a4-32b3d0e1b8e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8795 - loss: 0.4191 - val_accuracy: 0.9656 - val_loss: 0.1167\n","Epoch 2/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9672 - loss: 0.1062 - val_accuracy: 0.9727 - val_loss: 0.0934\n","Epoch 3/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9786 - loss: 0.0698 - val_accuracy: 0.9718 - val_loss: 0.0873\n","Epoch 4/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0516 - val_accuracy: 0.9759 - val_loss: 0.0764\n","Epoch 5/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9882 - loss: 0.0360 - val_accuracy: 0.9764 - val_loss: 0.0837\n","Epoch 6/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0311 - val_accuracy: 0.9759 - val_loss: 0.0832\n","Epoch 7/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0286 - val_accuracy: 0.9750 - val_loss: 0.0922\n","Epoch 8/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0220 - val_accuracy: 0.9760 - val_loss: 0.0916\n","Epoch 9/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0172 - val_accuracy: 0.9801 - val_loss: 0.0808\n","Epoch 10/10\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0158 - val_accuracy: 0.9791 - val_loss: 0.0880\n","313/313 - 1s - 2ms/step - accuracy: 0.9791 - loss: 0.0880\n","Test accuracy: 97.91%\n"]}],"source":["# Step 2: Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","\n","# Step 3: Define Neural Architecture Model (Already defined in the code below)\n","# Define input dimensions for MNIST dataset (28x28 images, grayscale)\n","input_shape = (28, 28, 1)\n","\n","# Step 4: Load and preprocess the dataset\n","# Load MNIST data\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Normalize the images by dividing by 255 (pixel values range from 0 to 255)\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","# Reshape the images to be compatible with the network (adding channels dimension)\n","x_train = x_train.reshape(-1, 28, 28, 1)\n","x_test = x_test.reshape(-1, 28, 28, 1)\n","\n","# One-hot encode the labels (categorical labels to binary matrix form)\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Step 5: Build the feed-forward neural network model\n","model = models.Sequential()\n","\n","# Flatten the input data (28x28 image to a 1D vector of 784 features)\n","model.add(layers.Flatten(input_shape=input_shape))\n","\n","# Add the first hidden layer with 128 neurons and ReLU activation function\n","model.add(layers.Dense(128, activation='relu'))\n","\n","# Add the second hidden layer with 64 neurons and ReLU activation function\n","model.add(layers.Dense(64, activation='relu'))\n","\n","# Output layer with 10 neurons (one for each digit 0-9) and softmax activation\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","# Step 6: Compile the model\n","# Use Adam optimizer, sparse categorical crossentropy loss, and accuracy as the evaluation metric\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Step 7: Train the model\n","# Train the model with the training dataset, using a batch size of 32 and 10 epochs\n","model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))\n","\n","# Step 8: Evaluate the model\n","# Evaluate the model on the test data and get the accuracy\n","test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n","\n","# Step 9: Display the results\n","print(f'Test accuracy: {test_acc * 100:.2f}%')\n","\n","# Step 10: End the process\n","# The process is complete as we've trained and evaluated the model\n"]},{"cell_type":"code","source":["# Step 2: Import necessary libraries\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.optimizers import Adam\n","\n","# Step 3: Define Neural Architecture Model (Already defined in the code below)\n","# Define input dimensions for MNIST dataset (28x28 images, grayscale)\n","input_shape = (28, 28, 1)\n","\n","# Step 4: Load and preprocess the dataset\n","# Load MNIST data\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# Normalize the images by dividing by 255 (pixel values range from 0 to 255)\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","# Reshape the images to be compatible with the network (adding channels dimension)\n","x_train = x_train.reshape(-1, 28, 28, 1)\n","x_test = x_test.reshape(-1, 28, 28, 1)\n","\n","# One-hot encode the labels (categorical labels to binary matrix form)\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Step 5: Build the feed-forward neural network model\n","model = models.Sequential()\n","\n","# Flatten the input data (28x28 image to a 1D vector of 784 features)\n","model.add(layers.Flatten(input_shape=input_shape))\n","\n","# Add the first hidden layer with 128 neurons and ReLU activation function\n","model.add(layers.Dense(128, activation='relu'))\n","\n","# Add Dropout after the first hidden layer\n","model.add(layers.Dropout(0.3))  # Dropout rate of 30%\n","\n","# Add the second hidden layer with 64 neurons and ReLU activation function\n","model.add(layers.Dense(64, activation='relu'))\n","\n","# Add Dropout after the second hidden layer\n","model.add(layers.Dropout(0.3))  # Dropout rate of 30%\n","\n","# Output layer with 10 neurons (one for each digit 0-9) and softmax activation\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","# Step 6: Compile the model\n","# Use Adam optimizer with a learning rate hyperparameter, sparse categorical crossentropy loss, and accuracy as the evaluation metric\n","learning_rate = 0.001  # Hyperparameter for the learning rate\n","optimizer = Adam(learning_rate=learning_rate)\n","\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Step 7: Train the model\n","# Train the model with the training dataset, using a batch size of 32 and 15 epochs (modified from 10)\n","epochs = 15  # Hyperparameter for number of epochs\n","model.fit(x_train, y_train, epochs=epochs, batch_size=32, validation_data=(x_test, y_test))\n","\n","# Step 8: Evaluate the model\n","# Evaluate the model on the test data and get the accuracy\n","test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n","\n","# Step 9: Display the results\n","print(f'Test accuracy: {test_acc * 100:.2f}%')\n","\n","# Step 10: End the process\n","# The process is complete as we've trained and evaluated the model\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hd-kQZoefU5A","executionInfo":{"status":"ok","timestamp":1738564142578,"user_tz":-330,"elapsed":142187,"user":{"displayName":"Shreyansh Jain","userId":"06728667211778416802"}},"outputId":"3b14b0a5-8f1b-491a-8b17-75b00eae2d8a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 0.6542 - val_accuracy: 0.9545 - val_loss: 0.1456\n","Epoch 2/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.2060 - val_accuracy: 0.9694 - val_loss: 0.1031\n","Epoch 3/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1553 - val_accuracy: 0.9717 - val_loss: 0.0912\n","Epoch 4/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1339 - val_accuracy: 0.9730 - val_loss: 0.0865\n","Epoch 5/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9639 - loss: 0.1215 - val_accuracy: 0.9772 - val_loss: 0.0788\n","Epoch 6/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9661 - loss: 0.1120 - val_accuracy: 0.9762 - val_loss: 0.0812\n","Epoch 7/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9693 - loss: 0.0996 - val_accuracy: 0.9783 - val_loss: 0.0730\n","Epoch 8/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9713 - loss: 0.0924 - val_accuracy: 0.9742 - val_loss: 0.0808\n","Epoch 9/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.0896 - val_accuracy: 0.9767 - val_loss: 0.0811\n","Epoch 10/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0874 - val_accuracy: 0.9792 - val_loss: 0.0725\n","Epoch 11/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0805 - val_accuracy: 0.9767 - val_loss: 0.0797\n","Epoch 12/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0786 - val_accuracy: 0.9778 - val_loss: 0.0772\n","Epoch 13/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0777 - val_accuracy: 0.9783 - val_loss: 0.0759\n","Epoch 14/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0773 - val_accuracy: 0.9782 - val_loss: 0.0778\n","Epoch 15/15\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0701 - val_accuracy: 0.9785 - val_loss: 0.0816\n","313/313 - 1s - 2ms/step - accuracy: 0.9785 - loss: 0.0816\n","Test accuracy: 97.85%\n"]}]}]}